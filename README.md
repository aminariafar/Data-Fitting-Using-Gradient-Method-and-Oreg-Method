# ðŸ“ˆ Data Fitting Using Gradient Descent & Orthogonal Regression

This project investigates **two approaches to data fitting**:  
- **Gradient Descent** â€” an iterative optimization method.  
- **Orthogonal Regression** â€” a regression technique that accounts for errors in both variables.  

It applies these methods to both **synthetic datasets** and a **real-world dataset** (Boston Housing).

---

## âœ¨ Key Contents

### Notebook
- **`gradient_oreg.ipynb`**  
  - Part 1: Gradient Descent method  
    - Procedures for multiple synthetic datasets (Data1, Data2, Data3, Data4)  
  - Part 2: Orthogonal Regression method  
    - Further experiments on additional datasets (Data3, Data4, Data5, Data6)  
  - Application to the **Boston Housing dataset** for regression and dimensionality analysis  

### Datasets (`data/` folder)
- `data1.txt` â€“ `data6.txt`: Synthetic regression datasets  
- `Data3.txt` â€“ `Data6.txt`: Extra datasets for orthogonal regression  
- `boston.csv`: Classic real-world dataset for regression tasks  

---

## ðŸ§± Project Structure
```
Data-Fitting-Using-Gradient-Method-and-Oreg-Method-main/
â”œâ”€â”€ gradient_oreg.ipynb   # Main Jupyter notebook
â””â”€â”€ data/
    â”œâ”€â”€ data1.txt â€¦ data6.txt   # Synthetic datasets
    â”œâ”€â”€ Data3.txt â€¦ Data6.txt   # Orthogonal regression datasets
    â””â”€â”€ boston.csv              # Boston Housing dataset
```

---

## ðŸŽ¯ Research Context
This project was prepared as part of a **university study on numerical optimization and regression**.  
It demonstrates how iterative optimization (gradient descent) compares with analytical techniques (orthogonal regression).

---

ðŸ“š Made for research & learning â€” blending math, code, and data for deeper insights into regression.
